<!doctype html>
<html class="no-js">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1" charset="UTF-8">
    <title>responseFormat</title>
<link href="../../../images/logo-icon.svg" rel="icon" type="image/svg">    <script>var pathToRoot = "../../../";</script>
    <script>document.documentElement.classList.replace("no-js","js");</script>
    <script>const storage = localStorage.getItem("dokka-dark-mode")
    if (storage == null) {
        const osDarkSchemePreferred = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
        if (osDarkSchemePreferred === true) {
            document.getElementsByTagName("html")[0].classList.add("theme-dark")
        }
    } else {
        const savedDarkMode = JSON.parse(storage)
        if(savedDarkMode === true) {
            document.getElementsByTagName("html")[0].classList.add("theme-dark")
        }
    }
    </script>
<script type="text/javascript" src="https://unpkg.com/kotlin-playground@1/dist/playground.min.js" async></script>
<script type="text/javascript" src="../../../scripts/sourceset_dependencies.js" async></script>
<link href="../../../styles/style.css" rel="Stylesheet">
<link href="../../../styles/main.css" rel="Stylesheet">
<link href="../../../styles/prism.css" rel="Stylesheet">
<link href="../../../styles/logo-styles.css" rel="Stylesheet">
<link href="../../../styles/font-jb-sans-auto.css" rel="Stylesheet">
<script type="text/javascript" src="../../../scripts/clipboard.js" async></script>
<script type="text/javascript" src="../../../scripts/navigation-loader.js" async></script>
<script type="text/javascript" src="../../../scripts/platform-content-handler.js" async></script>
<script type="text/javascript" src="../../../scripts/main.js" defer></script>
<script type="text/javascript" src="../../../scripts/prism.js" async></script>
<script type="text/javascript" src="../../../scripts/symbol-parameters-wrapper_deferred.js" defer></script></head>
<body>
    <div class="root">
<nav class="navigation" id="navigation-wrapper">
    <div class="navigation--inner">
        <div class="navigation-title">
            <button class="menu-toggle" id="menu-toggle" type="button">toggle menu</button>
            <div class="library-name">
<a class="library-name--link" href="../../../index.html">
                            openai-kotlin
                    </a>            </div>
            <div class="library-version">
            </div>
        </div>
        <div class="filter-section" id="filter-section">
                <button class="platform-tag platform-selector common-like" data-active="" data-filter=":openai-core:dokkaHtmlPartial/commonMain">common</button>
        </div>
    </div>
    <div class="navigation-controls">
        <button class="navigation-controls--btn navigation-controls--theme" id="theme-toggle-button" type="button">switch theme</button>
        <div class="navigation-controls--btn navigation-controls--search" id="searchBar" role="button">search in API</div>
    </div>
</nav>
        <div id="container">
            <div class="sidebar" id="leftColumn">
                <div class="sidebar--inner" id="sideMenu"></div>
            </div>
            <div id="main">
<div class="main-content" data-page-type="member" id="content" pageids="openai-core::com.aallam.openai.api.assistant/AssistantRequest/responseFormat/#/PointingToDeclaration//-1970785397">
  <div class="breadcrumbs"><a href="../../index.html">openai-core</a><span class="delimiter">/</span><a href="../index.html">com.aallam.openai.api.assistant</a><span class="delimiter">/</span><a href="index.html">AssistantRequest</a><span class="delimiter">/</span><span class="current">responseFormat</span></div>
  <div class="cover ">
    <h1 class="cover"><span>response</span><wbr><span><span>Format</span></span></h1>
  </div>
  <div class="platform-hinted " data-platform-hinted="data-platform-hinted"><div class="content sourceset-dependent-content" data-active="" data-togglable=":openai-core:dokkaHtmlPartial/commonMain"><div class="symbol monospace"><div class="block"><div class="block"><span class="token annotation builtin">@</span><span data-unresolved-link="kotlinx.serialization/SerialName///PointingToDeclaration/"><span class="token annotation builtin">SerialName</span></span><span class="token punctuation">(</span><span>value<span class="token operator"> = </span><span class="breakable-word"><span class="token string">"response_format"</span></span></span><wbr><span class="token punctuation">)</span></div></div><span class="token keyword">val </span><a href="response-format.html">responseFormat</a><span class="token operator">: </span><a href="../-assistant-response-format/index.html">AssistantResponseFormat</a><span class="token operator">?</span><span class="token operator"> = </span>null</div><p class="paragraph">Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.</p><p class="paragraph">Setting to <a href="../-assistant-response-format/-companion/-j-s-o-n_-s-c-h-e-m-a.html">AssistantResponseFormat.JSON_SCHEMA</a> enables Structured Outputs which ensures the model will match your supplied JSON schema.</p><p class="paragraph">Structured Outputs (<a href="../-assistant-response-format/-companion/-j-s-o-n_-s-c-h-e-m-a.html">AssistantResponseFormat.JSON_SCHEMA</a>) are available in our latest large language models, starting with GPT-4o:</p><ol><li><p class="paragraph">gpt-4o-mini-2024-07-18 and later</p></li><li><p class="paragraph">gpt-4o-2024-08-06 and later</p></li></ol><p class="paragraph">Older models like gpt-4-turbo and earlier may use JSON mode (<a href="../-assistant-response-format/-companion/-j-s-o-n_-o-b-j-e-c-t.html">AssistantResponseFormat.JSON_OBJECT</a>) instead.</p><p class="paragraph">Setting to <a href="../-assistant-response-format/-companion/-j-s-o-n_-o-b-j-e-c-t.html">AssistantResponseFormat.JSON_OBJECT</a> enables JSON mode, which guarantees the message the model generates is valid JSON.</p><p class="paragraph">important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.</p></div></div>
</div>
      <div class="footer">
        <span class="go-to-top-icon"><a href="#content" id="go-to-top-link"></a></span><span>Â© 2026 Copyright</span><span class="pull-right"><span>Generated by </span><a href="https://github.com/Kotlin/dokka"><span>dokka</span><span class="padded-icon"></span></a></span>
      </div>
            </div>
        </div>
    </div>
</body>
</html>

