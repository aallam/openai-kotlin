package com.aallam.openai.api.classification

import com.aallam.openai.api.ExperimentalOpenAI
import com.aallam.openai.api.completion.Logprobs
import com.aallam.openai.api.engine.EngineId
import kotlinx.serialization.SerialName
import kotlinx.serialization.Serializable

@Deprecated("Classification APIs are deprecated")
@ExperimentalOpenAI
@Serializable
public data class ClassificationRequest(

    /**
     * The engine to use for completion.
     */
    @SerialName("model") public val model: EngineId,

    /**
     * Query to be classified.
     */
    @SerialName("query") public val query: String,

    /**
     * A list of examples with labels, in the following format:
     * `[["The movie is so interesting.", "Positive"], ["It is quite boring.", "Negative"], ...]`
     *
     * All the label strings will be normalized to be capitalized.
     * You should specify either examples or file, but not both.
     *
     * Defaults to `null`.
     */
    @SerialName("examples") public val examples: List<LabeledExample>? = null,

    /**
     * The ID of the uploaded file that contains training examples.
     * You should specify either examples or file, but not both.
     *
     * Defaults to `null`.
     */
    @SerialName("file") public val file: String? = null,

    /**
     * The set of categories being classified. If not specified, candidate labels will be automatically collected from
     * the examples you provide. All the label strings will be normalized to be capitalized.
     *
     * Defaults to `null`.
     */
    @SerialName("labels") public val labels: List<String>? = null,

    /**
     * ID of the engine to use for semantic search.
     *
     * Defaults to ada.
     */
    @SerialName("search_model") public val searchModel: EngineId? = null,

    /**
     * What sampling `temperature` to use. Higher values mean the model will take more risks.
     * Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.
     *
     * Defaults to 0
     */
    @SerialName("temperature") public val temperature: Double? = null,

    /**
     * Include the log probabilities on the [logprobs] most likely tokens, as well the chosen tokens.
     * For example, if [logprobs] is 10, the API will return a list of the 10 most likely tokens.
     * The API will always return the logprob of the sampled token, so there may be up to [logprobs]+1 elements
     * in the response.
     *
     * When [logprobs] is set, completion` will be automatically added into expand to get the logprobs
     *
     * Defaults to `null`.
     */
    @SerialName("logprobs") public val logprobs: Logprobs? = null,

    /**
     * The maximum number of examples to be ranked by semantic search when using `file`.
     * Setting it to a higher value leads to improved accuracy but with increased latency and cost.
     *
     * Defaults to 200
     */
    @SerialName("max_examples") public val maxExamples: Int? = null,

    /**
     * Modify the likelihood of specified tokens appearing in the completion.
     *
     * Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias`
     * value from -100 to 100. You can use this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text
     * to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling.
     * The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood
     * of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
     *
     * As an example, you can pass `{"50256": -100}` to prevent the `<|endoftext|> token from being generated.
     *
     * Defaults to `null`.
     */
    @SerialName("logit_bias") public val logitBias: Map<String, Int>? = null,

    /**
     * If set to `true`, the returned JSON will include a "prompt" field containing the final prompt that was used
     * to request a completion. This is mainly useful for debugging purposes.
     *
     * Defaults to `false`.
     */
    @SerialName("return_prompt") public val returnPrompt: Boolean? = null,

    /**
     * A special boolean flag for showing metadata.
     * If set to true, each document entry in the returned JSON will contain a "metadata" field.
     *
     * This flag only takes effect when file is set.
     *
     * Defaults to `false`.
     */
    @SerialName("return_metadata") public val returnMetadata: Boolean? = null,

    /**
     * If an object name is in the list, we provide the full information of the object; otherwise, we only provide
     * the object ID. Currently we support completion and file objects for expansion.
     *
     * Defaults to empty list.
     */
    @SerialName("expand") public val expand: List<String>? = null
)
